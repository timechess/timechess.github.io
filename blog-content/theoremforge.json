{
  "slug": "theoremforge",
  "content": "\n# Introduction\n\nFormal theorem proving with proof assistants such as Lean has recently attracted growing attention from AI researchers. This trend is a natural consequence of two parallel developments: the maturation of modern proof assistants and the rise of large language models (LLMs).\n\nTraditionally, the mathematics community has not taken formal theorem proving seriously, largely because of the immense effort required to formalize existing results. Modern mathematics is complex in both breadth and depth; to formalize a cutting-edge result often means reconstructing an extensive foundation. Moreover, proof assistants lack the flexibility of LLMs: they cannot “read between the lines,” and the details of formalization can be tedious.\n\nYet the landscape is changing. With Lean 4 and its rapidly growing library, Mathlib, we no longer need to build everything from scratch. The ecosystem provides a robust foundation, enabling mathematicians and non-mathematicians alike to engage with formalization. This has broadened the community: researchers in AI, computer science, and beyond now explore formal methods. In particular, LLM researchers view formal verifiers as a way to reduce hallucinations in mathematical reasoning, while members of the formalization community see AI as a tool to accelerate the process itself.\n\nThese developments have given rise to several research directions, which can be roughly grouped into two categories:\n\n- **Human-in-the-loop systems**, where AI assists mathematicians in the formalization process.\n- **Autonomous agents**, where AI acts independently to perform formalization tasks.\n\nBefore delving into specific applications, it is important to emphasize that formalization is inherently a **systematic and engineering-heavy project**. The conventional workflow mirrors blueprint writing in mathematics: researchers first sketch a proof in natural language, then formalize intermediate results step by step. While certain subtasks can be framed as clean, self-contained problems, assembling them into a coherent formalization is far more challenging. Many existing systems perform impressively on benchmarks but remain impractical for serious projects.\n\nTypical human-in-the-loop applications include tools like [LeanSearch](https://leansearch.net), a search engine for theorems and definitions in Mathlib. Because Lean formalization heavily relies on its standard library, efficiency depends on familiarity with Mathlib. Searching documentation is therefore a constant and sometimes tedious task. Tools such as LeanSearch, [LeanExplore](https://www.leanexplore.com/), and [LeanStateSearch](https://premise-search.com) (developed by our team) alleviate this burden by enabling natural language queries or proof state queries. These tools cannot eliminate the intellectual demands of formalization, but they streamline routine steps and improve efficiency.\n\nThe second class of applications targets **autoformalization**: translating informal mathematical statements into formal Lean syntax. Examples include [Herald](https://arxiv.org/abs/2410.10878), [Kimina-Autoformalizer](https://huggingface.co/AI-MO/Kimina-Autoformalizer-7B), and [Goedel-Formalizer-V2](https://huggingface.co/Goedel-LM/Goedel-Formalizer-V2-32B). Autoformalization is critical because the quality of a formalized statement strongly influences the difficulty of proof construction. However, it remains a difficult problem. Compiler checks are insufficient for evaluation, while semantic validation by experts is costly. Most current works rely on LLMs as judges, which is unreliable. Developing robust evaluation methods is still an open challenge.\n\nThe third class involves **automated theorem proving**: generating proofs from formal statements. Approaches can be divided into **stepwise provers**, which generate tactic sequences with feedback from the Lean compiler, and **whole-proof generators**, which attempt to produce an entire proof in one shot. Although stepwise provers more closely mimic human proof development, they are computationally demanding. Whole-proof generators, leveraging the reasoning capabilities of modern LLMs, often achieve stronger results. The current state-of-the-art, [Seed-Prover](https://arxiv.org/abs/2507.23726), combines test-time scaling with compiler-guided self-correction, achieving impressive benchmark performance.\n\nWith these advances, more sophisticated agentic systems are emerging. A notable milestone is [Gauss](https://www.math.inc/gauss), which successfully formalized the strong [Prime Number Theorem](https://en.wikipedia.org/wiki/Prime_number_theorem). Guided by a human-written blueprint and refined through iterative feedback, Gauss illustrates the potential of AI agents in serious formalization tasks, even though it remains a human-in-the-loop system.\n\nOverall, human-in-the-loop applications have proven most practical so far. Autonomous provers, while conceptually exciting, are often limited to small-scale demonstrations or require prohibitive computational resources. Nonetheless, the potential of autonomous systems is immense. In software engineering, agentic approaches such as Devin, Cursor, and Cline have already demonstrated the power of AI code agents. There is reason to believe that theorem formalization—though complex—may be within reach of similar systems. What is needed is a mature agentic framework with context management, tool integration, and workflow design. In this blog, I call such a system **TheoremForge**.\n\n# Blueprint\n\nBefore designing the system, we must clarify its inputs and outputs. Mathematical formalization typically starts from a main theorem; supportive lemmas and definitions are introduced as the proof requires. In practice a project lead prepares a formal **blueprint** or dependency graph: a proof sketch that records relationships among theorems, lemmas, and definitions, and — when available — short natural-language proof sketches that explain the intended reasoning. A well-structured blueprint guides contributors of varying experience levels and makes machine-generated formalizations easier to inspect and accept. Therefore, the system’s output should include a comprehensive informal blueprint paired with formalization code; a typical input is a research paper that contains a main theorem and a complete proof.\n\nFrom this input/output view, the system decomposes into three core components:\n\n- **Blueprint Generator.** Produces a structured blueprint of the formalization project guided by the informal proof.\n- **Autoformalizer.** Translates the blueprint’s statements (definitions, lemmas, theorems) into formal code aligned with the target library (e.g., Mathlib).\n- **Automated Theorem Prover (ATP).** Attempts to produce machine-checkable proofs from the formal statements and the informal proof sketch.\n\n## Blueprint Generator\n\nThe blueprint generator is both the most important and the most challenging component. It must parse the provided proof, identify intermediate claims and definitions, and rewrite the material in a “blueprint style” suitable for decomposition into implementable tasks. Concretely, a good generator:\n\n- extracts nodes (theorems/lemmas/definitions) and edges (dependencies),\n- annotates each node with a short proof sketch, difficulty estimate, and suggested granularity, and\n- proposes several alternative proof paths when appropriate.\n\nThe generator may need to consult external literature to fill gaps or suggest lemmas not present in the original paper. Crucially, the blueprint is a living artifact: it will be revised during formalization. The agent should update the blueprint in response to failure reports and diagnostics produced by the autoformalizer or the ATP — a role humans played in the Gauss workflow.\n\n## Autoformalizer\n\nAlthough automated provers attract more attention, the quality of statement formalization often has greater practical impact. The autoformalizer’s task is to produce formal, library-compatible statements that faithfully capture the informal intent and are convenient for subsequent proof search. Key requirements:\n\n- align names and types to the target library (reduce “reinventing” of concepts),\n- produce statements that are semantically correct and proof-friendly, and\n- provide confidence signals (type checks, library linkings, short proof attempts).\n\nMost current autoformalizers are trained on competition-style problems; academic mathematics poses different challenges (richer notation, heavier dependency on existing libraries). Better evaluation is also needed: compiler acceptance is necessary but not sufficient; human review is expensive; relying on LLMs as judges is fragile. Practical improvements include retrieval-augmented generation, chain-of-thought prompts, and self-correction loops (generate → test → revise). Among the three components, the engineering burden for a usable autoformalizer is relatively light, making it a good practical starting point.\n\n## Automated Theorem Prover\n\nModern open-source provers can handle many problems with proofs on the order of tens to a few hundred tactic steps. With a good blueprint that decomposes a project into manageable claims, these provers can produce significant progress (as Gauss demonstrated).\n\nFor an agentic system the important capability is not any single design choice, but **feedback**: the ATP should admit failure modes, produce actionable diagnostics, and return structured feedback to the blueprint generator so the decomposition can be revised and retried.\n\n## Cooperation and workflow\n\nThese components should not run as a rigid pipeline but as cooperating agents that share context and update a single project state (versioned blueprint, artifact store, and proof cache). Each component can be trained or engineered independently, but the system benefits from integrated context management, standardized failure messages, and an orchestration loop that supports retries, lemma discovery, and human review. In my PhD I plan to build these components step by step. From autoformalizer, to ATP, and finally the blueprint generator.\n\n# End\n\nAs a realistic problem for a PhD student, I need at least three papers to graduate. This blueprint describes a system which I believe could support publications more than that number. My plan is one publication paired with one blog, and this blog serves as the starting point of my PhD research.\n\nHope everything goes well.\n",
  "title": "TheoremForge: A Blueprint Towards Autoformalization of Research-Level Mathematics",
  "date": "2025-9-22",
  "description": "In this blog I will describe the blueprint of developing agentic systems for autoformalization of research-level mathematics.",
  "author": [
    "timechess"
  ],
  "tags": [
    "AI4Math",
    "Lean"
  ],
  "draft": false,
  "navigation": {
    "prevPost": null,
    "nextPost": {
      "slug": "lean_intro",
      "title": "A Minimal Guide for Theorem Proving in Lean 4: Introduction of Basic Concepts",
      "description": "In this article, we will go through the basic concepts of Lean 4 to understand the simplest proof."
    }
  }
}